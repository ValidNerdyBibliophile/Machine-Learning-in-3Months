{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cRFNwZh8PNfx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZS9LQY6zPNf9"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ck4j_ROmPNf-",
    "outputId": "4925639a-9edf-43a8-fc46-51aa80b972a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z6KofVbZPNgB",
    "outputId": "a6f9b831-e21d-4db6-fb09-1d4c1b17d440",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "SepalLengthCm    0\n",
       "SepalWidthCm     0\n",
       "PetalLengthCm    0\n",
       "PetalWidthCm     0\n",
       "Species          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rMEUscnLPNgC"
   },
   "outputs": [],
   "source": [
    "x=data.drop(columns=\"Species\")\n",
    "y=data[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q7SKVbXrPNgE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PY9D6WeXPNgF"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  probA_\n",
      " |  \n",
      " |  probB_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(kernel=\"linear\",C=1)\n",
    "model.fit(xtrain,ytrain)\n",
    "ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JI7rs727PNgF",
    "outputId": "d247cefe-f1f7-4e4c-b6a8-004a6532ba5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc=accuracy_score(ytest,ypred)\n",
    "print(\"Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(ytest,ypred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BnDtVLtHPNgG",
    "outputId": "b83da9f1-320a-4544-f599-0225d2cadbde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00         6\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVoOObnKPNgH"
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CR3EJnkPPNgM"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "model=SVC()\n",
    "\n",
    "#paramters\n",
    "kernel=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C=[100,50,10,1,0.1,0.01]\n",
    "gamma=['scale']\n",
    "\n",
    "#grid\n",
    "grid={\"kernel\":kernel,\"C\":C,\"gamma\":gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TxD2GLmRPNgN"
   },
   "outputs": [],
   "source": [
    "#cv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv=RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch cv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_cv=GridSearchCV(estimator=model,param_grid=grid,cv=cv,scoring='accuracy',n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result\n",
    "res=grid_cv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972222222222222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SVM on Diabetes Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
