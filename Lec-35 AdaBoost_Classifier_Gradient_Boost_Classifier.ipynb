{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2u10FecEziO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9WZcu3BEziY"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQzx8XqxEzib",
    "outputId": "cee05ef1-6313-4b71-c061-3da5a4f781fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDESvCjhEzid"
   },
   "outputs": [],
   "source": [
    "x=df.drop(columns=[\"Outcome\"])\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3px3QV_vEzid"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P_lkOwMEzie"
   },
   "source": [
    "## AdaBoost\n",
    "\n",
    "Adaptive boosting or AdaBoost is one of the simplest boosting algorithms. Usually, decision trees are used for modelling. Multiple sequential models are created, each correcting the errors from the last model. AdaBoost assigns weights to the observations which are incorrectly predicted and the subsequent model works to predict these values correctly.\n",
    "\n",
    "Below are the steps for performing the AdaBoost algorithm:\n",
    "\n",
    "    1.Initially, all observations in the dataset are given equal weights.\n",
    "    2.A model is built on a subset of data.\n",
    "    3.Using this model, predictions are made on the whole dataset.\n",
    "    4.Errors are calculated by comparing the predictions and actual values.\n",
    "    5.While creating the next model, higher weights are given to the data points which were predicted incorrectly.\n",
    "    6.Weights can be determined using the error value. For instance, higher the error more is the weight assigned to the observation.\n",
    "    7.This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmw3UTKhEzif"
   },
   "source": [
    "AdaBoost can be used to boost the performance of any machine learning algorithm. It is best used with weak learners. These are models that achieve accuracy just above random chance on a classification problem.\n",
    "\n",
    "The most suited and therefore most common algorithm used with AdaBoost are decision trees with one level. Because these trees are so short and only contain one decision for classification, they are often called decision stumps.\n",
    "\n",
    "Each instance in the training dataset is weighted. The initial weight is set to:\n",
    "\n",
    "#### weight(xi) = 1/n\n",
    "\n",
    "Where xi is the i’th training instance and n is the number of training instances.\n",
    "\n",
    "\n",
    "## Train One Model\n",
    "\n",
    "A weak classifier (decision stump) is prepared on the training data using the weighted samples. \n",
    "\n",
    "The misclassification rate is calculated for the trained model. Traditionally, this is calculated as:\n",
    "\n",
    "#### error = (correct – N) / N\n",
    "\n",
    "Where error is the misclassification rate, correct are the number of training instance predicted correctly by the model and N is the total number of training instances. For example, if the model predicted 78 of 100 training instances correctly the error or misclassification rate would be (78-100)/100 or 0.22.\n",
    "\n",
    "This is modified to use the weighting of the training instances:\n",
    "\n",
    "#### error = sum(w(i) * terror(i)) / sum(w)\n",
    "\n",
    "Which is the weighted sum of the misclassification rate, where w is the weight for training instance i and terror is the prediction error for training instance i which is 1 if misclassified and 0 if correctly classified.\n",
    "\n",
    "For example, if we had 3 training instances with the weights 0.01, 0.5 and 0.2. The predicted values were 1, 1 and 1, and the actual output variables in the instances were 1, 0 and 1, then the terrors would be 0, 1, and 0. The misclassification rate would be calculated as:\n",
    "\n",
    "#### error = (0.01*0 + 0.5*1 + 0.2*0) / (0.01 + 0.5 + 0.2)\n",
    "\n",
    "or\n",
    "\n",
    "#### error = 0.704\n",
    "\n",
    "A stage value is calculated for the trained model which provides a weighting for any predictions that the model makes. The stage value for a trained model is calculated as follows:\n",
    "\n",
    "#### stage = ln((1-error) / error)\n",
    "\n",
    "Where stage is the stage value used to weight predictions from the model, ln() is the natural logarithm and error is the misclassification error for the model. The effect of the stage weight is that more accurate models have more weight or contribution to the final prediction.\n",
    "\n",
    "The training weights are updated giving more weight to incorrectly predicted instances, and less weight to correctly predicted instances.\n",
    "\n",
    "For example, the weight of one training instance (w) is updated using:\n",
    "\n",
    "#### w = w * exp(stage * terror)\n",
    "\n",
    "Where w is the weight for a specific training instance, exp() is the numerical constant e or Euler’s number raised to a power, stage is the misclassification rate for the weak classifier and terror is the error the weak classifier made predicting the output variable for the training instance, evaluated as:\n",
    "\n",
    "#### terror = 0 if(y == p), otherwise 1\n",
    "\n",
    "Where y is the output variable for the training instance and p is the prediction from the weak learner.\n",
    "\n",
    "This has the effect of not changing the weight if the training instance was classified correctly and making the weight slightly larger if the weak learner misclassified the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rx-oyTpcEzih",
    "outputId": "9289ad3a-8ab4-438f-93f7-8d45a325ba0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(xtrain, ytrain)\n",
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phPHPOJoEzii",
    "outputId": "2d993a3d-50b6-4c05-fcf9-788fb3debb19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2337416300445292"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(xtrain, ytrain)\n",
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UIJ8EbEEzij"
   },
   "source": [
    "Parameters\n",
    "\n",
    "    base_estimators:\n",
    "        It helps to specify the type of base estimator, that is, the machine learning algorithm to be used as base learner.\n",
    "    n_estimators:\n",
    "        It defines the number of base estimators.\n",
    "        The default value is 10, but you should keep a higher value to get better performance.\n",
    "    learning_rate:\n",
    "        This parameter controls the contribution of the estimators in the final combination.\n",
    "        There is a trade-off between learning_rate and n_estimators.\n",
    "    max_depth:\n",
    "        Defines the maximum depth of the individual estimator.\n",
    "        Tune this parameter for best performance.\n",
    "    n_jobs\n",
    "        Specifies the number of processors it is allowed to use.\n",
    "        Set value to -1 for maximum processors allowed.\n",
    "    random_state :\n",
    "        An integer value to specify the random data split.\n",
    "        A definite value of random_state will always produce same results if given with same parameters and training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij-MkVWwEzik"
   },
   "source": [
    "## Gradient Boosting (GBM)\n",
    "\n",
    "Gradient Boosting or GBM is another ensemble machine learning algorithm that works for both regression and classification problems. GBM uses the boosting technique, combining a number of weak learners to form a strong learner. Regression trees used as a base learner, each subsequent tree in series is built on the errors calculated by the previous tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-4PidqEEzil",
    "outputId": "ed3c6120-2c8a-4054-bc77-45b9d4b2201d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.8116883116883117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       107\n",
      "           1       0.70      0.68      0.69        47\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.78      0.78      0.78       154\n",
      "weighted avg       0.81      0.81      0.81       154\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "ypred=model.predict(xtest)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "print(\"Accuracy is :\",accuracy_score(ytest,ypred))\n",
    "print(classification_report(ytest,ypred))\n",
    "cm=confusion_matrix(ytest,ypred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AdaBoost Classifier and Gradient Boost Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
